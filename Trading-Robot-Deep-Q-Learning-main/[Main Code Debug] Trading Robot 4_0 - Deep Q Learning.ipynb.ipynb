{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Robo Trade 2.0 Usando Deep Q-Learning\n",
        "\n",
        "Segunda tentativa de criação de uma rede neural para prever oscilações no mercado de ação.\n",
        "\n",
        "Desta vez tentaremos usar Deep Q-Learning, usando Q-Networks.\n",
        "\n",
        "<hr>\n",
        "\n",
        "## Funcionamento\n",
        "\n",
        "Nossa rede neural terá a seguinte configuração:\n",
        "\n",
        "* **Entrada:** os últimos X estados escolhidos pela variável ```window_size```.\n",
        "* **Saídas:** Comprar, Vender, Esperar.\n",
        "\n",
        "<hr>\n",
        "\n",
        "## Classes e suas funções\n",
        "### **AI_Trader:**\n",
        "- **Construtor:**\n",
        "\n",
        "  Inicializa o agente que atuará no nosso ambiente.\n",
        "\n",
        "- **Model Builder:**\n",
        "\n",
        "  Modela a arquitetura da nossa rede neural de acordo com nossas escolhas.\n",
        "\n",
        "- **Trade:**\n",
        "\n",
        "  Função de decide se o agente irá executar um previsão usando a Q-Network ou executará uma ação gananciosa aleatória.\n",
        "\n",
        "  Esta também é a função que retorna a resposta final da rede neural (Comprar, Vender ou Esperar).\n",
        "\n",
        "- **Batch_Trade:**\n",
        "\n",
        "  Função que realiza o treinamendo do lote de memórias.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QSFHJ1IYFx3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# EXECUTAR NA PRIMEIRA EXECUÇÃO!"
      ],
      "metadata": {
        "id": "ejU_s_D7j6b6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install yfinance"
      ],
      "metadata": {
        "id": "ukXLTyxQA4oQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "792c8a91-c11a-49e2-c1e6-ee02ae8e17e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yfinance\n",
            "  Downloading yfinance-0.1.70-py2.py3-none-any.whl (26 kB)\n",
            "Collecting requests>=2.26\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.10)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.21.5)\n",
            "Collecting lxml>=4.5.1\n",
            "  Downloading lxml-4.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 11.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yfinance) (1.15.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.0.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2021.10.8)\n",
            "Installing collected packages: requests, lxml, yfinance\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed lxml-4.8.0 requests-2.27.1 yfinance-0.1.70\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EXECUTAR NA PRIMEIRA EXECUÇÃO!\n",
        "\n",
        "# Bitcoin Hora a hora - Data download\n",
        "!gdown --id '1VQry5JMRcuZ_BStIX8-FB8n4zFuDNUjk'"
      ],
      "metadata": {
        "id": "6wn_pMN7kC2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas_datareader as data_reader\n",
        "\n",
        "from tqdm import tqdm_notebook, tqdm\n",
        "from collections import deque\n",
        "\n",
        "import pandas\n",
        "from pandas_datareader import data as pdr\n",
        "import yfinance as yfin\n",
        "import datetime\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "debug = 1"
      ],
      "metadata": {
        "id": "QTd21an3F2a5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining our Deep Q-Learning Trader\n",
        "\n",
        "class AI_Trader():  \n",
        "\n",
        "# -----------------------------------------------------------------------\n",
        "\n",
        "  # CONSTRUTOR\n",
        "\n",
        "  def __init__(self, state_size, action_space=3, model_name=\"AITrader\"):\n",
        "    \n",
        "    self.state_size = state_size # Tamanho da entrada da rede neural \n",
        "    self.action_space = action_space # Espaço de ação será 3, Comprar, Vender, Sem Ação (Tamanho da saída da rede neural)\n",
        "    self.memory = deque(maxlen=2000) # Memória com 2000 posições. A função Deque permite adicionar elementos ao final, enquanto remove elementos do início.\n",
        "    self.inventory = [] # Terá as comprar que já fizemos\n",
        "    self.model_name = model_name # Nome do modelo para o Keras\n",
        "    \n",
        "    self.gamma = 0.95 # Parâmetro que ajudará a maximizar a recompensa\n",
        "    self.epsilon = 1.0 # Taxa de aleatoriedade para atitudes ganacioas do algorítimo.\n",
        "    self.epsilon_final = 0.01 # Taxa final reduzida\n",
        "    self.epsilon_decay = 0.995 # Velocidade de decaimento da taxa\n",
        "\n",
        "    self.model = self.model_builder() # Inicializa um modelo e de rede neural e salva na classe\n",
        "\n",
        "# -----------------------------------------------------------------------\n",
        "\n",
        "  # DEFININDO A REDE NEURAL\n",
        "\n",
        "  def model_builder(self):\n",
        "        \n",
        "    model = tf.keras.models.Sequential()      \n",
        "    model.add(layers.Dense(units=32, activation='relu', input_dim=self.state_size))\n",
        "    model.add(layers.Dense(units=64, activation='relu'))\n",
        "    model.add(layers.Dense(units=128, activation='relu'))\n",
        "    model.add(layers.Dense(units=self.action_space, activation='linear')) # De maneira geral, teremos 3 saída na rede geral (número de espaços de ação)\n",
        "\n",
        "\n",
        "    model.compile(loss='mse', optimizer=keras.optimizers.Adam(learning_rate=0.001)); # Compilamos o modelo\n",
        "\n",
        "    return model # Retornamos o modelo pela função.\n",
        "\n",
        "# -----------------------------------------------------------------------\n",
        "\n",
        "  # FUNÇÃO DE TRADE\n",
        "  # Usa o Epsilon e um número aleatório para definir se usará um dado aleatório ou a previsão da rede.\n",
        "\n",
        "  def trade(self, state):\n",
        "    if(debug):{print('TRADE FUNCTION:')}\n",
        "\n",
        "    if random.random() <= self.epsilon:\n",
        "      if(debug):{print('Entrou - Random')}\n",
        "      return random.randrange(self.action_space)\n",
        "\n",
        "    if(debug):{print('Vai Treinar Modelo')}\n",
        "    actions = self.model.predict(state)\n",
        "    if(debug):{print('Actions = ', actions)}\n",
        "    if(debug):{print('Actions Argmax = ', np.argmax(actions[0]))}\n",
        "\n",
        "    return np.argmax(actions[0])\n",
        "\n",
        "# -----------------------------------------------------------------------\n",
        "\n",
        "  # LOTE DE TREINAMENTO\n",
        "\n",
        "  # Definindo o modelo para treinamento do lote\n",
        "\n",
        "  def batch_train(self, batch_size): # Função que tem o tamanho do lote como argumento\n",
        "\n",
        "    batch = [] # Iremos usar a memória como lote, por isso iniciamos com uma lista vazia\n",
        "\n",
        "    # Iteramos sobre a memória, adicionando seus elementos ao lote batch\n",
        "    for i in range(len(self.memory) - batch_size + 1, len(self.memory)): \n",
        "      batch.append(self.memory[i])\n",
        "\n",
        "    # Agora temos um lote de dados e devemos iterar sobre cada estado, recompensa,\n",
        "    # proximo_estado e conclusão do lote e treinar o modelo com isso.\n",
        "    for state, action, reward, next_state, done in batch:\n",
        "      reward = reward\n",
        "\n",
        "      # Se não estivermos no último agente da memória, então calculamos a\n",
        "      # recompensa descontando a recompensa total da recompensa atual.\n",
        "      if not done:\n",
        "        reward = reward + self.gamma * np.amax(self.model.predict(next_state)[0])\n",
        "\n",
        "      # Fazemos uma previsão e alocamos à varivel target\n",
        "      target = self.model.predict(state)\n",
        "      target[0][action] = reward\n",
        "\n",
        "      # Treinamos o modelo com o estado, usando a previsão como resultado esperado.\n",
        "      self.model.fit(state, target, epochs=1, verbose=0)\n",
        "\n",
        "    # Por fim decrementamos o epsilon a fim de gradativamente diminuir tentativas ganaciosas. \n",
        "    if self.epsilon > self.epsilon_final:\n",
        "      self.epsilon *= self.epsilon_decay\n",
        "\n",
        "# -----------------------------------------------------------------------\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------\n",
        "    \n"
      ],
      "metadata": {
        "id": "nMWegySnF4jR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stock Market Data Preprocessing\n",
        "\n",
        "# Definiremos algumas funções uteis\n",
        "\n",
        "# Sigmoid\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + math.exp(-x))\n",
        "\n",
        "# Função para formatar texto\n",
        "def stock_price_format(n):\n",
        "  if n < 0:\n",
        "    return \"- # {0:2f}\".format(abs(n))\n",
        "  else:\n",
        "    return \"$ {0:2f}\".format(abs(n))\n",
        "\n",
        "# Busca dados no Yahoo Finance\n",
        "# Formato data = \"yyyy-mm-dd\"\n",
        "def dataset_loader(stock_name, initial_date, final_date):\n",
        "\n",
        "  yfin.pdr_override()\n",
        "\n",
        "  dataset = pdr.get_data_yahoo(stock_name, start=initial_date, end=final_date)\n",
        "  \n",
        "  start_date = str(dataset.index[0]).split()[0]\n",
        "  end_date = str(dataset.index[1]).split()[0]\n",
        "  \n",
        "  close = dataset['Close']\n",
        "  \n",
        "  return close"
      ],
      "metadata": {
        "id": "mlwcYt-3fItG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# State Creator\n",
        "\n",
        "Primeiro vamos traduzir o problema para um ambiente de aprendizado por reforço.\n",
        "\n",
        "* Cada ponto no gráfico é um ponto flutuante que representa o valor no momento do tempo.\n",
        "\n",
        "* Devemos prever o que acontecerá no próximo período de tempo, usando umas das 3 possibilidades de ação: compra, venda ou sem ação (esperar)\n",
        "\n",
        "Inicialmente vamos usar uma janela de 5 estados anteriores, para tentar prever o próximo.\n",
        "\n",
        "```windows_size = 5```\n",
        "\n",
        "Ao invés vez de prever valores reais para nosso alvo, queremos prever uma de nossas 3 ações.\n",
        "\n",
        "Em seguida, mudamos nossos estados de entrada para diferenças nos preços das ações, que representarão as mudanças de preços ao longo do tempo.\n"
      ],
      "metadata": {
        "id": "GOeEOux6ncU1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# State Creator\n",
        "\n",
        "\n",
        "def state_creator(data, timestep, window_size):\n",
        "\n",
        "  # O index incial (starting_id) será o timestep (passos/dias que já foram dados)\n",
        "  # menos o tamanho da janela, que serão os dias olhados para trás.\n",
        "  starting_id = timestep - window_size + 1\n",
        "\n",
        "  if(debug):{print('Timestep = ', timestep)}\n",
        "  if(debug):{print('Window_size = ', window_size)}\n",
        "  if(debug):{print(\"Starting id = \", starting_id)}\n",
        "\n",
        "  if starting_id >= 0:\n",
        "    windowed_data = data[starting_id: timestep + 1]\n",
        "\n",
        "    if(debug):{print(\"Entrou no >=0. Starting id = \", starting_id)}\n",
        "    if(debug):{print(\"windowed_data = \", windowed_data)}\n",
        "\n",
        "  else:\n",
        "    windowed_data =- starting_id * [data[0]] + list(data[0:timestep + 1])\n",
        "\n",
        "    if(debug):{print(\"Entrou no Else. Starting id = \", starting_id)}\n",
        "    if(debug):{print(\"w_d = \", windowed_data)}\n",
        "\n",
        "  state = [] # Criou uma array vazia para o estado\n",
        "\n",
        "  if(debug):{print('Vai entrar no FOR de normalização:')}\n",
        "\n",
        "  for i in range(window_size - 1):\n",
        "    if(debug):{print('windowed_data[i + 1] = ', windowed_data[i+1])}\n",
        "    if(debug):{print('windowed_data[i] = ', windowed_data[i])}\n",
        "\n",
        "    state.append(sigmoid(windowed_data[i + 1] - windowed_data[i]))\n",
        "\n",
        "    if(debug):{print('state = ',state)}\n",
        "\n",
        "  return np.array([state])"
      ],
      "metadata": {
        "id": "v6ZXzg8GjLM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LuglY8HcbGWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading a Dataset\n",
        "\n",
        "# CONFIGURAÇÕES DE IMPORTAÇÃO DE DADOS\n",
        "\n",
        "# NOME DA AÇÃO\n",
        "STOCK_NAME = \"WEGE3.SA\"\n",
        "\n",
        "# DATA INCIAL\n",
        "INITIAL_DATE = \"2021-01-01\"\n",
        "\n",
        "# DATA FINAL\n",
        "today = datetime.date.today()\n",
        "FINAL_DATE = today.strftime(\"%Y-%m-%d\") # Escolhe a data final como hoje\n",
        "\n",
        "data = dataset_loader(STOCK_NAME, INITIAL_DATE, FINAL_DATE);\n",
        "\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "subYTitYk75X",
        "outputId": "3b7e8e08-6440-49a0-f5cf-aa1dc45a7a35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Date\n",
              "2021-01-04    37.310001\n",
              "2021-01-05    39.599998\n",
              "2021-01-06    40.650002\n",
              "2021-01-07    42.330002\n",
              "2021-01-08    44.889999\n",
              "                ...    \n",
              "2022-02-14    30.440001\n",
              "2022-02-15    32.880001\n",
              "2022-02-16    31.299999\n",
              "2022-02-17    30.650000\n",
              "2022-02-18    29.809999\n",
              "Name: Close, Length: 282, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the Q-Learning Trading Agent\n",
        "\n",
        "window_size = 10\n",
        "episodes = 2\n",
        "\n",
        "batch_size = 32\n",
        "data_samples = len(data) - 1\n",
        "\n",
        "trader = AI_Trader(window_size)\n",
        "trader.model.summary()\n",
        "\n",
        "# if(debug):{print('Entrou - Random')}\n",
        "\n",
        "trader.epsilon = 1\n"
      ],
      "metadata": {
        "id": "lNC1nFOYsk20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb3a0ca7-df7f-40f7-a1f8-0b8551d65284"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 32)                352       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               8320      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,171\n",
            "Trainable params: 11,171\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "debug = 1\n",
        "\n",
        "state = state_creator(data, 0, window_size + 1)\n",
        "\n",
        "total_profit = 0;\n",
        "trader.inventory = []\n",
        "\n",
        "t=14\n",
        "\n"
      ],
      "metadata": {
        "id": "Vf5nkxISaAIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trader.epsilon = 0.1\n",
        "\n",
        "\n",
        "if(debug):{print('------ MAKE TRADE:')}\n",
        "\n",
        "action = trader.trade(state)\n",
        "\n",
        "if(debug):{print('ACTION = ', action)}\n",
        "\n",
        "if(debug):{print('------ FIND NEXT STATE:')}\n",
        "\n",
        "next_state = state_creator(data, t+1, window_size + 1)\n",
        "reward = 0\n",
        "\n",
        "# action = 1\n",
        "\n",
        "\n",
        "\n",
        "if(debug):{print('------ TAKING ACTION:')}\n",
        "if(debug):{print('Tader Inventory = ', trader.inventory)}\n",
        "\n",
        "\n",
        "if action == 1: #Buying\n",
        "  if(debug):{print('ACTION = 1 (BUY)')}\n",
        "\n",
        "  trader.inventory.append(data[t])\n",
        "  print(\"AI Trader bought: \", stock_price_format(data[t]))\n",
        "\n",
        "elif action == 2 and len(trader.inventory) > 0: #Selling\n",
        "  if(debug):{print('ACTION = 0 (SELL)')}\n",
        "\n",
        "  buy_price = trader.inventory.pop(0)\n",
        "  if(debug):{print('Buy Price = ', buy_price)}\n",
        "  \n",
        "  reward = max(data[t] - buy_price, 0)\n",
        "  if(debug):{print('dat[t] = ', data[t])}\n",
        "  if(debug):{print('Reward = ', reward)}\n",
        "\n",
        "  total_profit += data[t] - buy_price\n",
        "  if(debug):{print('Total Pofit = ', total_profit)}\n",
        "  print(\"AI Trader sold: \", stock_price_format(data[t]), \" Profit: \" + stock_price_format(data[t] - buy_price) )\n",
        "\n",
        "\n",
        "if t == data_samples - 1:\n",
        "    done = True\n",
        "else:\n",
        "    done = False\n",
        "\n",
        "if(debug):{print('------ SAVING MEMORY:')}\n",
        "\n",
        "trader.memory.append((state, action, reward, next_state, done))\n",
        "if(debug):{print('Memory = ', trader.memory)}\n",
        "\n",
        "    \n",
        "state = next_state\n",
        "\n",
        "t = t+1\n",
        "\n",
        "# Se o tamanho da memória for maior que o tamanho do lote que definimos\n",
        "# Então vamos treinar a rede, passando o tamanho do lote como argumento\n",
        "if(debug):{print('Memory Len= ', len(trader.memory))}\n",
        "\n",
        "if len(trader.memory) > batch_size:\n",
        "  trader.batch_train(batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "or9tBxH1dqRN",
        "outputId": "a09124d4-6441-4a59-f019-17aaccef0cad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------ MAKE TRADE:\n",
            "TRADE FUNCTION:\n",
            "Vai Treinar Modelo\n",
            "Actions =  [[0.02785273 0.19441126 0.09472802]]\n",
            "Actions Argmax =  1\n",
            "ACTION =  1\n",
            "------ FIND NEXT STATE:\n",
            "Timestep =  25\n",
            "Window_size =  11\n",
            "Starting id =  15\n",
            "Entrou no >=0. Starting id =  15\n",
            "windowed_data =  Date\n",
            "2021-01-26    44.474998\n",
            "2021-01-27    44.345001\n",
            "2021-01-28    43.985001\n",
            "2021-01-29    41.895000\n",
            "2021-02-01    42.270000\n",
            "2021-02-02    42.615002\n",
            "2021-02-03    44.334999\n",
            "2021-02-04    42.785000\n",
            "2021-02-05    42.250000\n",
            "2021-02-08    42.750000\n",
            "2021-02-09    42.505001\n",
            "Name: Close, dtype: float64\n",
            "Vai entrar no FOR de normalização:\n",
            "windowed_data[i + 1] =  44.345001220703125\n",
            "windowed_data[i] =  44.474998474121094\n",
            "state =  [0.4675463773653247]\n",
            "windowed_data[i + 1] =  43.98500061035156\n",
            "windowed_data[i] =  44.345001220703125\n",
            "state =  [0.4675463773653247, 0.4109594181924409]\n",
            "windowed_data[i + 1] =  41.89500045776367\n",
            "windowed_data[i] =  43.98500061035156\n",
            "state =  [0.4675463773653247, 0.4109594181924409, 0.11007255941551251]\n",
            "windowed_data[i + 1] =  42.27000045776367\n",
            "windowed_data[i] =  41.89500045776367\n",
            "state =  [0.4675463773653247, 0.4109594181924409, 0.11007255941551251, 0.5926665999540697]\n",
            "windowed_data[i + 1] =  42.6150016784668\n",
            "windowed_data[i] =  42.27000045776367\n",
            "state =  [0.4675463773653247, 0.4109594181924409, 0.11007255941551251, 0.5926665999540697, 0.5854048654014796]\n",
            "windowed_data[i + 1] =  44.334999084472656\n",
            "windowed_data[i] =  42.6150016784668\n",
            "state =  [0.4675463773653247, 0.4109594181924409, 0.11007255941551251, 0.5926665999540697, 0.5854048654014796, 0.848128502220217]\n",
            "windowed_data[i + 1] =  42.78499984741211\n",
            "windowed_data[i] =  44.334999084472656\n",
            "state =  [0.4675463773653247, 0.4109594181924409, 0.11007255941551251, 0.5926665999540697, 0.5854048654014796, 0.848128502220217, 0.1750863783562263]\n",
            "windowed_data[i + 1] =  42.25\n",
            "windowed_data[i] =  42.78499984741211\n",
            "state =  [0.4675463773653247, 0.4109594181924409, 0.11007255941551251, 0.5926665999540697, 0.5854048654014796, 0.848128502220217, 0.1750863783562263, 0.3693515098913705]\n",
            "windowed_data[i + 1] =  42.75\n",
            "windowed_data[i] =  42.25\n",
            "state =  [0.4675463773653247, 0.4109594181924409, 0.11007255941551251, 0.5926665999540697, 0.5854048654014796, 0.848128502220217, 0.1750863783562263, 0.3693515098913705, 0.6224593312018546]\n",
            "windowed_data[i + 1] =  42.505001068115234\n",
            "windowed_data[i] =  42.75\n",
            "state =  [0.4675463773653247, 0.4109594181924409, 0.11007255941551251, 0.5926665999540697, 0.5854048654014796, 0.848128502220217, 0.1750863783562263, 0.3693515098913705, 0.6224593312018546, 0.4390548127367579]\n",
            "------ TAKING ACTION:\n",
            "Tader Inventory =  [44.345001220703125, 43.98500061035156, 42.27000045776367, 42.6150016784668, 44.334999084472656, 42.78499984741211]\n",
            "ACTION = 1 (BUY)\n",
            "AI Trader bought:  $ 42.750000\n",
            "------ SAVING MEMORY:\n",
            "Memory =  deque([(array([[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]]), 2, 0.0, array([[0.82053855, 0.5262258 , 0.44892922, 0.13528696, 0.95369075,\n",
            "        0.21332468, 0.38936058, 0.37168435, 0.65926035, 0.49749949]]), False), (array([[0.82053855, 0.5262258 , 0.44892922, 0.13528696, 0.95369075,\n",
            "        0.21332468, 0.38936058, 0.37168435, 0.65926035, 0.49749949]]), 2, 0, array([[0.5262258 , 0.44892922, 0.13528696, 0.95369075, 0.21332468,\n",
            "        0.38936058, 0.37168435, 0.65926035, 0.49749949, 0.46754638]]), False), (array([[0.5262258 , 0.44892922, 0.13528696, 0.95369075, 0.21332468,\n",
            "        0.38936058, 0.37168435, 0.65926035, 0.49749949, 0.46754638]]), 1, 0, array([[0.44892922, 0.13528696, 0.95369075, 0.21332468, 0.38936058,\n",
            "        0.37168435, 0.65926035, 0.49749949, 0.46754638, 0.41095942]]), False), (array([[0.44892922, 0.13528696, 0.95369075, 0.21332468, 0.38936058,\n",
            "        0.37168435, 0.65926035, 0.49749949, 0.46754638, 0.41095942]]), 1, 0, array([[0.13528696, 0.95369075, 0.21332468, 0.38936058, 0.37168435,\n",
            "        0.65926035, 0.49749949, 0.46754638, 0.41095942, 0.11007256]]), False), (array([[0.13528696, 0.95369075, 0.21332468, 0.38936058, 0.37168435,\n",
            "        0.65926035, 0.49749949, 0.46754638, 0.41095942, 0.11007256]]), 0, 0, array([[0.95369075, 0.21332468, 0.38936058, 0.37168435, 0.65926035,\n",
            "        0.49749949, 0.46754638, 0.41095942, 0.11007256, 0.5926666 ]]), False), (array([[0.95369075, 0.21332468, 0.38936058, 0.37168435, 0.65926035,\n",
            "        0.49749949, 0.46754638, 0.41095942, 0.11007256, 0.5926666 ]]), 1, 0, array([[0.21332468, 0.38936058, 0.37168435, 0.65926035, 0.49749949,\n",
            "        0.46754638, 0.41095942, 0.11007256, 0.5926666 , 0.58540487]]), False), (array([[0.21332468, 0.38936058, 0.37168435, 0.65926035, 0.49749949,\n",
            "        0.46754638, 0.41095942, 0.11007256, 0.5926666 , 0.58540487]]), 1, 0, array([[0.38936058, 0.37168435, 0.65926035, 0.49749949, 0.46754638,\n",
            "        0.41095942, 0.11007256, 0.5926666 , 0.58540487, 0.8481285 ]]), False), (array([[0.38936058, 0.37168435, 0.65926035, 0.49749949, 0.46754638,\n",
            "        0.41095942, 0.11007256, 0.5926666 , 0.58540487, 0.8481285 ]]), 1, 0, array([[0.37168435, 0.65926035, 0.49749949, 0.46754638, 0.41095942,\n",
            "        0.11007256, 0.5926666 , 0.58540487, 0.8481285 , 0.17508638]]), False), (array([[0.37168435, 0.65926035, 0.49749949, 0.46754638, 0.41095942,\n",
            "        0.11007256, 0.5926666 , 0.58540487, 0.8481285 , 0.17508638]]), 1, 0, array([[0.65926035, 0.49749949, 0.46754638, 0.41095942, 0.11007256,\n",
            "        0.5926666 , 0.58540487, 0.8481285 , 0.17508638, 0.36935151]]), False), (array([[0.65926035, 0.49749949, 0.46754638, 0.41095942, 0.11007256,\n",
            "        0.5926666 , 0.58540487, 0.8481285 , 0.17508638, 0.36935151]]), 0, 0, array([[0.49749949, 0.46754638, 0.41095942, 0.11007256, 0.5926666 ,\n",
            "        0.58540487, 0.8481285 , 0.17508638, 0.36935151, 0.62245933]]), False), (array([[0.49749949, 0.46754638, 0.41095942, 0.11007256, 0.5926666 ,\n",
            "        0.58540487, 0.8481285 , 0.17508638, 0.36935151, 0.62245933]]), 1, 0, array([[0.46754638, 0.41095942, 0.11007256, 0.5926666 , 0.58540487,\n",
            "        0.8481285 , 0.17508638, 0.36935151, 0.62245933, 0.43905481]]), False)], maxlen=2000)\n",
            "Memory Len=  11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trader.memory"
      ],
      "metadata": {
        "id": "qsNKovGFdwt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = [1,2,100,4,5,6,7]\n",
        "\n",
        "print(np.argmax(a))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpkR0-oOdxKK",
        "outputId": "6b861507-651c-4b21-9ddd-6bb6cd60bb25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Fi0_FBmedw9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a Training Loop\n",
        "\n",
        "# Vamos iterar sobre todos episódios\n",
        "\n",
        "\n",
        "\n",
        "for episode in range(1, episodes + 1):\n",
        "  \n",
        "  print(\"Episode: {}/{}\".format(episode, episodes))\n",
        "  \n",
        "  state = state_creator(data, 0, window_size + 1)\n",
        "  \n",
        "  total_profit = 0\n",
        "  trader.inventory = []\n",
        "  \n",
        "  for t in tqdm(range(data_samples)):\n",
        "    \n",
        "    action = trader.trade(state)\n",
        "    \n",
        "    next_state = state_creator(data, t+1, window_size + 1)\n",
        "    reward = 0\n",
        "    \n",
        "    if action == 1: #Buying\n",
        "      trader.inventory.append(data[t])\n",
        "      print(\"AI Trader bought: \", stock_price_format(data[t]))\n",
        "      \n",
        "    elif action == 2 and len(trader.inventory) > 0: #Selling\n",
        "      buy_price = trader.inventory.pop(0)\n",
        "      \n",
        "      reward = max(data[t] - buy_price, 0)\n",
        "      total_profit += data[t] - buy_price\n",
        "      print(\"AI Trader sold: \", stock_price_format(data[t]), \" Profit: \" + stock_price_format(data[t] - buy_price) )\n",
        "      \n",
        "    if t == data_samples - 1:\n",
        "      done = True\n",
        "    else:\n",
        "      done = False\n",
        "      \n",
        "    trader.memory.append((state, action, reward, next_state, done))\n",
        "    \n",
        "    state = next_state\n",
        "    \n",
        "    if done:\n",
        "      print(\"########################\")\n",
        "      print(\"TOTAL PROFIT: {}\".format(total_profit))\n",
        "      print(\"########################\")\n",
        "    \n",
        "    if len(trader.memory) > batch_size:\n",
        "      trader.batch_train(batch_size)\n",
        "      \n",
        "  if episode % 10 == 0:\n",
        "    trader.model.save(\"ai_trader_{}.h5\".format(episode))\n",
        "    "
      ],
      "metadata": {
        "id": "_nZd_fkru7y3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "[SI] BITCOIN ROBOT 4.0 DEBUG - Deep Q Learning - Gabriel e Vinicius",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}